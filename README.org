* Dictate ðŸ”´

A background speech-to-text dictation tool written in Clojure using
Babashka. This tool provides seamless speech-to-text functionality by
recording audio in the background and transcribing it using OpenAI's
Whisper API.

Dictate now supports continuous recording with automatic silence
detection, providing a seamless hands-free dictation experience.

** Features

- *Background Service*: Runs as a background process for continuous dictation
- *Toggle Control*: Easy on/off switching for recording mode
- *OpenAI Whisper Integration*: High-quality speech-to-text transcription
- *Configurable Audio Input*: Support for different audio devices
- *System Integration*: Works with xbindkeys and i3status
- *Visual Feedback*: State indicator for active/inactive modes

** Requirements

- [[https://babashka.org/][Babashka]] - Clojure interpreter for scripting
- =sox= - Swiss Army Knife of sound processing utilities
- =xdotool= - X11 automation tool for typing text
- =curl= - HTTP client for API requests
- OpenAI API key for Whisper transcription

** Installation

Easily install with [[https://github.com/babashka/bbin][bbin]]

#+begin_src bash
bbin install io.github.200ok-ch/dictate
#+end_src

** Usage

*** Basic Commands

#+begin_src bash
# Start the background service
dictate --service

# Toggle recording on/off
dictate --toggle

# Show help
dictate --help
#+end_src

*** Configuration Options

- =-a, --device=DEVICE= - Audio input device [default: default]
- =-d, --delay=MS= - Typing delay in milliseconds [default: 25]
- =-m, --model=MODEL= - Whisper model [default: whisper-1]
- =-p, --api-path=PATH= - API endpoint path [default: /v1/audio/transcriptions]
- =-r, --api-root=URL= - API root URL [default: https://api.openai.com]

*** Examples

#+begin_src bash
# Start service with default settings
dictate --service

# Start service with specific audio device
dictate --service --device=hw:1,0

# Toggle recording mode
dictate --toggle
#+end_src

** System Integration

*** xbindkeys Configuration

Add this to your =~/.xbindkeysrc= for keyboard shortcuts:

#+begin_src
"dictate --toggle"
  Pause
#+end_src

*** i3status Configuration

Add this to your i3status config for status bar integration:

#+begin_src
order += "read_file dictate"

read_file dictate {
    path = "~/.dictate.state"
    format = "%content"
}
#+end_src

** State Management

The tool uses a simple state file (=~/.dictate.state=) to track
whether recording is active or inactive:

- Active state: Contains the ðŸ”´ indicator
- Inactive state: Empty file

** Similar Projects & Acknowledgements

- [[https://github.com/yohasebe/whisper-stream][whisper-stream]]
- [[https://github.com/igorpejic/linux-speech-to-text][linux-speech-to-text]]
- [[https://github.com/200ok-ch/ok-audio-transcription][ok-audio-transcription]]
- [[https://github.com/ideasman42/nerd-dictation][nerd-dictation]]
- [[https://github.com/chalda-pnuzig/emojis.json][emojis.json]]

** License

This project is maintained by [[https://200ok.ch/][200ok GmbH]].

** Configuration

You can customize Dictate's behavior by creating a =dictate.yml=
configuration file in the *SAME* directory where you call =dictate=.

The values in this example are also the defaults.

Example:

#+begin_src yaml
# audio
device: "default"                    # Audio input device (e.g., "default", "hw:1,0")
# silence
volume: 2                            # Maximum volume of silence in percentage
duration: 1.5                        # Minimum duration of silence in secs
# transcription
api-root: "https://api.openai.com"   # API root URL
api-path: "/v1/audio/transcriptions" # API endpoint path
api-key: "sk-..."                    # Your OpenAI API key
model: "gpt-4o-transcribe"           # Whisper model to use
# typing
delay: 25                            # Typing delay in milliseconds
# misc
i3status: false                      # Whether to reload i3status on toggle
emojis: false                        # Dis-/enable emoji feature
#+end_src
